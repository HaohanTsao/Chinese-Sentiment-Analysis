{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"17Mp0aXZJpIVS3LMkRllRje6zxMCD26u8","authorship_tag":"ABX9TyMfHWt6um1xcZGguqVpy4WM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Fine Tuning BERT for Sentiment Analysis"],"metadata":{"id":"6hSzHyUjR2IT"}},{"cell_type":"markdown","source":["此檔案僅為建立training pipeline 與測試的檔案"],"metadata":{"id":"kI_TpP2Fr45l"}},{"cell_type":"code","source":["pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MSUyshOSzPn","executionInfo":{"status":"ok","timestamp":1685541779043,"user_tz":-480,"elapsed":16542,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"dae1ca67-6288-49f5-8b74-1d9ca9177039"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"]}]},{"cell_type":"code","source":["# package\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import torch\n","from transformers import BertModel, BertTokenizer"],"metadata":{"id":"BROMFDKASESS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re"],"metadata":{"id":"xjBW90Q70ggc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns"],"metadata":{"id":"Tx348QmaGE6l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/python機器學習專案')"],"metadata":{"id":"q_wtbwcFftj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 準備測試資料\n","selected_columns = ['content', 'sentiment']\n","folder_path = 'raw_data'\n","file_path = ['db2022_hw5_dcard_job.csv', 'db2022_hw5_dcard_food.csv'] \n","bert_test_data = pd.DataFrame()\n","for filename in os.listdir(folder_path):\n","  if filename in file_path:\n","    df_temp = pd.read_csv(f'{folder_path}/{filename}')\n","    bert_test_data = pd.concat([bert_test_data, df_temp[selected_columns]], ignore_index=True)"],"metadata":{"id":"NhxUIXHjiSZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["valid_sentiments = ['N', 'M', 'P']\n","bert_test_data = bert_test_data[bert_test_data['sentiment'].isin(valid_sentiments)]"],"metadata":{"id":"ZzxyNWRLsEQf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_test_data.drop_duplicates(inplace=True)\n","bert_test_data = bert_test_data.dropna(axis=0, how='any', subset=['content'])"],"metadata":{"id":"UTw1rnqDysuC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_test_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugV6T7vizBIA","executionInfo":{"status":"ok","timestamp":1685541791374,"user_tz":-480,"elapsed":16,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"c37f366a-0a36-4b73-b838-e3a5c3bad09e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(77320, 2)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["bert_test_data[\"sentiment\"] = bert_test_data[\"sentiment\"].replace({'N': 0, 'M': 1, 'P': 2})"],"metadata":{"id":"BhxO7b_izfJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 文本清理函數\n","def text_clean(content):\n","  cleaned_content = content\n","  cleaned_content = re.sub(r'[\\n\\r]', '', cleaned_content) # 換行符號\n","  cleaned_content = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', cleaned_content) # 移除url\n","  cleaned_content = re.sub(r'<.*?>', '', cleaned_content) # 移除html標籤\n","  cleaned_content = re.sub(r'\\d+', '', cleaned_content) # 數字\n","  cleaned_content = re.sub(r'[^\\w\\s]', '', cleaned_content) # 移除標點符號\n","  cleaned_content = re.sub(r\"\\s+\", \"\", cleaned_content) # 清除空格\n","  return cleaned_content"],"metadata":{"id":"iAPODlaizvwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_test_data['cleaned_content'] = bert_test_data['content'].apply(text_clean)"],"metadata":{"id":"YfuBEW5N0erq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_test_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"Sl9u1r6B1wb6","executionInfo":{"status":"ok","timestamp":1685541798812,"user_tz":-480,"elapsed":10,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"ec203697-9d3e-4e16-c6ae-02299e0af3c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             content  sentiment  \\\n","0  https://megapx-assets.dcard.tw/images/5a86504a...          1   \n","1  聽說有水餃吃到飽 但為什麼沒有雞蛋吃到飽啊？ 我這個人最愛吃雞蛋了 一天最高紀錄可以吃25顆...          1   \n","2  https://megapx-assets.dcard.tw/images/8086527f...          1   \n","3  現在不管吃什麼泡麵（用煮的）都一定會加鮮奶！！！ 真的很好吃😂😂😂😂  拉麵道、辛拉麵、🍅泡...          2   \n","4  https://i.imgur.com/y9y3Nhv.jpg 唐揚雞烤飯糰 $45 唐揚炸...          1   \n","\n","                                     cleaned_content  \n","0                                                     \n","1  聽說有水餃吃到飽但為什麼沒有雞蛋吃到飽啊我這個人最愛吃雞蛋了一天最高紀錄可以吃顆如果能有這樣...  \n","2                                                     \n","3        現在不管吃什麼泡麵用煮的都一定會加鮮奶真的很好吃拉麵道辛拉麵泡麵各種泡麵都一定要加鮮奶  \n","4  唐揚雞烤飯糰唐揚炸雞叉燒豚骨拉麵這次價格在超商來說都偏貴比較推薦嚐鮮的是唐揚炸雞和烤飯糰唐揚...  "],"text/html":["\n","  <div id=\"df-37750018-f7c5-450d-a3ab-b84cedd18e7c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>sentiment</th>\n","      <th>cleaned_content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://megapx-assets.dcard.tw/images/5a86504a...</td>\n","      <td>1</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>聽說有水餃吃到飽 但為什麼沒有雞蛋吃到飽啊？ 我這個人最愛吃雞蛋了 一天最高紀錄可以吃25顆...</td>\n","      <td>1</td>\n","      <td>聽說有水餃吃到飽但為什麼沒有雞蛋吃到飽啊我這個人最愛吃雞蛋了一天最高紀錄可以吃顆如果能有這樣...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://megapx-assets.dcard.tw/images/8086527f...</td>\n","      <td>1</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>現在不管吃什麼泡麵（用煮的）都一定會加鮮奶！！！ 真的很好吃😂😂😂😂  拉麵道、辛拉麵、🍅泡...</td>\n","      <td>2</td>\n","      <td>現在不管吃什麼泡麵用煮的都一定會加鮮奶真的很好吃拉麵道辛拉麵泡麵各種泡麵都一定要加鮮奶</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://i.imgur.com/y9y3Nhv.jpg 唐揚雞烤飯糰 $45 唐揚炸...</td>\n","      <td>1</td>\n","      <td>唐揚雞烤飯糰唐揚炸雞叉燒豚骨拉麵這次價格在超商來說都偏貴比較推薦嚐鮮的是唐揚炸雞和烤飯糰唐揚...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37750018-f7c5-450d-a3ab-b84cedd18e7c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-37750018-f7c5-450d-a3ab-b84cedd18e7c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-37750018-f7c5-450d-a3ab-b84cedd18e7c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# 載入預訓練的模型\n","bert_model = BertModel.from_pretrained(\"/content/drive/MyDrive/python機器學習專案/model_file\")\n","tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/python機器學習專案/model_file\")"],"metadata":{"id":"UkgJnVs2fZyO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_sentence = \"這是一個測試的句子\""],"metadata":{"id":"0qCI5r9vtjPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = tokenizer.tokenize(sample_sentence)\n","token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(f' Sentence: {sample_sentence}')\n","print(f'   Tokens: {tokens}')\n","print(f'Token IDs: {token_ids}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaxweSI-uOdC","executionInfo":{"status":"ok","timestamp":1685541807938,"user_tz":-480,"elapsed":49,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"b47b7257-6cc5-4167-ab43-9a23d52701f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Sentence: 這是一個測試的句子\n","   Tokens: ['這', '是', '一', '個', '測', '試', '的', '句', '子']\n","Token IDs: [6857, 3221, 671, 943, 3947, 6275, 4638, 1368, 2094]\n"]}]},{"cell_type":"markdown","source":["### 下面這段是直接複製，參數的意義要再研究(長度等等)，encode_plus是把文本轉換為模型可理解的輸入格式"],"metadata":{"id":"sdpssfFy32O3"}},{"cell_type":"code","source":["encoding = tokenizer.encode_plus(\n","  sample_sentence,\n","  max_length=32,\n","  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n","  return_token_type_ids=False,\n","  pad_to_max_length=True,\n","  return_attention_mask=True,\n","  return_tensors='pt',  # Return PyTorch tensors\n",")\n","\n","encoding.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aArt9YJy30e3","executionInfo":{"status":"ok","timestamp":1685541807938,"user_tz":-480,"elapsed":46,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"50924bca-6286-4352-bf52-dc4aefde7d10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["print(len(encoding['input_ids'][0]))\n","encoding['input_ids'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhNZX1H_5qYH","executionInfo":{"status":"ok","timestamp":1685541807939,"user_tz":-480,"elapsed":40,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"be946077-a657-4115-bf64-f6116e00b3fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([ 101, 6857, 3221,  671,  943, 3947, 6275, 4638, 1368, 2094,  102,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["print(len(encoding['attention_mask'][0]))\n","encoding['attention_mask']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlyFjkt1569A","executionInfo":{"status":"ok","timestamp":1685541807939,"user_tz":-480,"elapsed":36,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"b64db75b-6b9a-4c0e-8fc7-c14ae42443a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["32\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# We can inverse the tokenization to have a look at the special tokens:\n","tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92IP24hE59RV","executionInfo":{"status":"ok","timestamp":1685541807939,"user_tz":-480,"elapsed":32,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"77c5b7f0-e140-459a-8e3f-ab237a9c3270"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," '這',\n"," '是',\n"," '一',\n"," '個',\n"," '測',\n"," '試',\n"," '的',\n"," '句',\n"," '子',\n"," '[SEP]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]',\n"," '[PAD]']"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["### Choosing Sequence Length，實際資料要再調整"],"metadata":{"id":"iWpl_ONZHHgR"}},{"cell_type":"code","source":["# 用一個更小的dataset 當測試\n","test_data = bert_test_data.head(2000)\n"],"metadata":{"id":"YmvQHpa4Mxid"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"PTo_8BvJS_ns"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 建立pytorch dataset"],"metadata":{"id":"CmtqVdaVVgpA"}},{"cell_type":"code","source":["class ContentDataset(Dataset):\n","\n","  def __init__(self, contents, targets, tokenizer, max_len):\n","    self.contents = contents\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","  \n","  def __len__(self):\n","    return len(self.contents)\n","  \n","  def __getitem__(self, item):\n","    content = str(self.contents[item])\n","    target = self.targets[item]\n","\n","    encoding = self.tokenizer.encode_plus(\n","      content,\n","      add_special_tokens=True,\n","      max_length=self.max_len,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      return_tensors='pt',\n","    )\n","\n","    return {\n","      'content_text': content,\n","      'input_ids': encoding['input_ids'].flatten(),\n","      'attention_mask': encoding['attention_mask'].flatten(),\n","      'targets': torch.tensor(target, dtype=torch.long)\n","    }"],"metadata":{"id":"ld0YOhy0JsS6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["分割資料"],"metadata":{"id":"Y4EswpdAVaHm"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","df_train, df_test = train_test_split(test_data, test_size=0.1, random_state=2023)\n","df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=2023)"],"metadata":{"id":"8MwgqEiMPlIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.shape, df_val.shape, df_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGvUmXIFSFfW","executionInfo":{"status":"ok","timestamp":1685541807941,"user_tz":-480,"elapsed":29,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"55590b0d-e88f-4674-939a-c208d38fd47e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1800, 3), (100, 3), (100, 3))"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["def create_data_loader(df, tokenizer, max_len, batch_size):\n","  ds = ContentDataset(\n","    contents=df['cleaned_content'].to_numpy(),\n","    targets=df['sentiment'].to_numpy(),\n","    tokenizer=tokenizer,\n","    max_len=max_len\n","  )\n","\n","  return DataLoader(\n","    ds,\n","    batch_size=batch_size,\n","    num_workers=4\n","  )"],"metadata":{"id":"Jj7K0ZsaSZo6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["這邊的batch size跟max_length先照抄"],"metadata":{"id":"hxqtFhUAWQkM"}},{"cell_type":"code","source":["BATCH_SIZE = 16\n","MAX_LENGTH = 160\n","train_data_loader = create_data_loader(df_train, tokenizer, MAX_LENGTH, BATCH_SIZE)\n","val_data_loader = create_data_loader(df_val, tokenizer, MAX_LENGTH, BATCH_SIZE)\n","test_data_loader = create_data_loader(df_test, tokenizer, MAX_LENGTH, BATCH_SIZE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsme7O6qVNTd","executionInfo":{"status":"ok","timestamp":1685541807941,"user_tz":-480,"elapsed":26,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"4af52c31-65f3-42cd-9b24-da8b42fdc781"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["# 看一下長相\n","data = next(iter(train_data_loader))\n","data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m87fVK0XWKBN","executionInfo":{"status":"ok","timestamp":1685541808469,"user_tz":-480,"elapsed":551,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"27d3ae1b-d35c-4ecb-bb2d-f52fabec0dd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['content_text', 'input_ids', 'attention_mask', 'targets'])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["print(data['content_text'][1])\n","print(data['input_ids'].shape)\n","print(data['attention_mask'].shape)\n","print(data['targets'].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70iJhKVEWOUt","executionInfo":{"status":"ok","timestamp":1685541985169,"user_tz":-480,"elapsed":10,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"0ab35747-0d8a-4950-b6eb-de8092e76368"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["想請問大家原本在師大的阿諾可麗餅對面有一個可麗餅的攤子不知道後來搬家搬到哪了查都查不到希望有人能指點迷津謝謝\n","torch.Size([16, 160])\n","torch.Size([16, 160])\n","torch.Size([16])\n"]}]},{"cell_type":"markdown","source":["## Sentiment classifier"],"metadata":{"id":"GF_SAbYaW7Fm"}},{"cell_type":"code","source":["encoding.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QS2_WREyZHrF","executionInfo":{"status":"ok","timestamp":1685542345840,"user_tz":-480,"elapsed":518,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"af3eda07-fa52-4e6d-b388-7b194326820c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask'])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# 用剛剛示範的句子看一下長相\n","temp = bert_model(\n","  input_ids=encoding['input_ids'], \n","  attention_mask=encoding['attention_mask']\n",")"],"metadata":{"id":"Rjt_dVWpXDv_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["last_hidden_state = temp.last_hidden_state\n","pooled_output = temp.pooler_output"],"metadata":{"id":"sm1lIo20u5s8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `last_hidden_state` is a sequence of hidden states of the last layer of the model. Obtaining the `pooled_output` is done by applying the [BertPooler](https://github.com/huggingface/transformers/blob/edf0582c0be87b60f94f41c659ea779876efc7be/src/transformers/modeling_bert.py#L426) on `last_hidden_state`:"],"metadata":{"id":"ck_qJwTGX23a"}},{"cell_type":"code","source":["last_hidden_state.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlK7XGEgX1Ik","executionInfo":{"status":"ok","timestamp":1685285000228,"user_tz":-480,"elapsed":25,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"7946880c-1add-4777-85b6-61b53a5c519f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 32, 768])"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["We have the hidden state for each of our 32 tokens (the length of our example sequence). But why 768? This is the number of hidden units in the feedforward-networks. We can verify that by checking the config:"],"metadata":{"id":"frRJIMKsv4Vg"}},{"cell_type":"code","source":["bert_model.config.hidden_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVNMpnDAwLjS","executionInfo":{"status":"ok","timestamp":1685285000229,"user_tz":-480,"elapsed":23,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"64f03010-d96c-4b0c-fd86-544a995cc72d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["768"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["You can think of the pooled_output as a summary of the content, according to BERT. Albeit, you might try and do better. Let's look at the shape of the output:"],"metadata":{"id":"RQufBoiCwc4B"}},{"cell_type":"code","source":["pooled_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJeSg0EFwgsg","executionInfo":{"status":"ok","timestamp":1685285000229,"user_tz":-480,"elapsed":18,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"f27eedb1-bf6f-43b5-a727-2f3e012c805b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 768])"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["We can use all of this knowledge to create a classifier that uses the BERT model:"],"metadata":{"id":"atGTrKDexAfu"}},{"cell_type":"code","source":["from torch import nn, optim\n","import torch.nn.functional as F"],"metadata":{"id":"OAK27xHYyFNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SentimentClassifier(nn.Module):\n","\n","  def __init__(self, n_classes):\n","    super(SentimentClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(\"/content/drive/MyDrive/python機器學習專案/model_file\")\n","    self.drop = nn.Dropout(p=0.3)\n","    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","  \n","  def forward(self, input_ids, attention_mask):\n","    outputs = self.bert(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","    )\n","    pooled_output = outputs[1]\n","    output = self.drop(pooled_output)\n","    return self.out(output)"],"metadata":{"id":"L2tjed_HxFXB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 架GPU"],"metadata":{"id":"CqmlCwxTIZmm"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_gW8okDm1TOx","executionInfo":{"status":"ok","timestamp":1685285000230,"user_tz":-480,"elapsed":15,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"236c4f78-6b42-49fc-d60d-67f254a98d59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun May 28 14:43:21 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"id":"5qpiheuw1ZLI","executionInfo":{"status":"ok","timestamp":1685285000741,"user_tz":-480,"elapsed":10,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"516056a4-8f33-4de6-a8cf-670645f1173e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["class_names = ['N', 'M', 'P']\n","model = SentimentClassifier(len(class_names))\n","model = model.to(device)"],"metadata":{"id":"eGkXCQjm2U0P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids = torch.tensor(data['input_ids']).to(device)\n","attention_mask = torch.tensor(data['attention_mask']).to(device)\n","# input_ids = torch.tensor(data['input_ids'])\n","# attention_mask = torch.tensor(data['attention_mask'])\n","\n","print(input_ids.shape) # batch size x seq length\n","print(attention_mask.shape) # batch size x seq length"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8niFaoUn3xC5","executionInfo":{"status":"ok","timestamp":1685285005736,"user_tz":-480,"elapsed":20,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"a573f963-8e9a-4da9-e448-1e4478dafec5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 160])\n","torch.Size([16, 160])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-43-fd7f036b06ac>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  input_ids = torch.tensor(data['input_ids']).to(device)\n","<ipython-input-43-fd7f036b06ac>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_mask = torch.tensor(data['attention_mask']).to(device)\n"]}]},{"cell_type":"markdown","source":["To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"],"metadata":{"id":"Xq3iqvaB4Uve"}},{"cell_type":"code","source":["print(type(input_ids))\n","print(type(attention_mask))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdxCSSn_868y","executionInfo":{"status":"ok","timestamp":1685285005737,"user_tz":-480,"elapsed":13,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"4d814e60-7484-4965-b2c2-ec670cfe1044"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["# 我也不知道這在幹嘛\n","# F.softmax(model(input_ids, attention_mask), dim=1)"],"metadata":{"id":"0NyggrUp4YUE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Trainning"],"metadata":{"id":"Df5K8Zw4-wTP"}},{"cell_type":"code","source":["from transformers import AdamW, get_linear_schedule_with_warmup"],"metadata":{"id":"S1_-B3P8-z4b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["為了重現BERT論文中的訓練過程，我們將使用Hugging Face提供的AdamW優化器。它修正了權重衰減（weight decay），因此與原始論文中的方法類似。我們還將使用沒有Warmup步驟的線性學習率調整器（scheduler）："],"metadata":{"id":"pto39yeM_-6J"}},{"cell_type":"markdown","source":["下面這段應該是調參數的重點"],"metadata":{"id":"5t9ssVIGBiGn"}},{"cell_type":"code","source":["EPOCHS = 10\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n","total_steps = len(train_data_loader) * EPOCHS\n","\n","scheduler = get_linear_schedule_with_warmup(\n","  optimizer,\n","  num_warmup_steps=0,\n","  num_training_steps=total_steps\n",")\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)\n","# loss_fn = nn.CrossEntropyLoss()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1n74vS7i_J3J","executionInfo":{"status":"ok","timestamp":1685285009214,"user_tz":-480,"elapsed":17,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"759afb74-c8dd-44e1-ac46-febdc026f77d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["我們如何得出所有的超參數？BERT的作者對微調模型提出了一些建議：\n","\n","Batch size：16、32\n","\n","學習率（Adam）：5e-5、3e-5、2e-5\n","\n","Number of epochs：2、3、4\n","\n","這邊將忽略對於訓練epochs數的建議，但遵循其他的建議。需要注意的是，增加批次大小可以顯著減少訓練時間，但會降低模型的準確度。\n","\n","讓我們繼續編寫一個輔助函數，用於訓練我們的模型一個epoch："],"metadata":{"id":"QOF-wH-A_dDE"}},{"cell_type":"code","source":["# using gpu\n","def train_epoch_gpu(\n","  model, \n","  data_loader, \n","  loss_fn, \n","  optimizer, \n","  device, \n","  scheduler, \n","  n_examples\n","):\n","  model = model.train()\n","\n","  losses = []\n","  correct_predictions = 0\n","  \n","  for d in data_loader:\n","    input_ids = d[\"input_ids\"].to(device)\n","    attention_mask = d[\"attention_mask\"].to(device)\n","    targets = d[\"targets\"].to(device)\n","\n","    outputs = model(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","\n","    _, preds = torch.max(outputs, dim=1)\n","    loss = loss_fn(outputs, targets)\n","\n","    correct_predictions += torch.sum(preds == targets)\n","    losses.append(loss.item())\n","\n","    loss.backward()\n","    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","    scheduler.step()\n","    optimizer.zero_grad()\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"Y0lL2pDUAN-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# using cpu\n","def train_epoch_cpu(\n","  model, \n","  data_loader, \n","  loss_fn, \n","  optimizer, \n","  scheduler, \n","  n_examples\n","):\n","  model = model.train()\n","\n","  losses = []\n","  correct_predictions = 0\n","  \n","  for d in data_loader:\n","    input_ids = d[\"input_ids\"]\n","    attention_mask = d[\"attention_mask\"]\n","    targets = d[\"targets\"]\n","\n","    outputs = model(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","\n","    _, preds = torch.max(outputs, dim=1)\n","    loss = loss_fn(outputs, targets)\n","\n","    correct_predictions += torch.sum(preds == targets)\n","    losses.append(loss.item())\n","\n","    loss.backward()\n","    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","    scheduler.step()\n","    optimizer.zero_grad()\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"KfGqZ2lM_wPE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["調度器在每次將一個batch餵給模型時被調用。我們通過使用clip_grad_norm_來避免梯度爆炸，對模型的梯度進行裁剪。這一段也可以做為調整的根據。\n","\n","這一段程式碼是訓練過程中的一個重要步驟，用於執行反向傳播和參數更新。\n","\n","1. `loss.backward()`: 這個方法計算損失對於模型參數的梯度。通過調用這個方法，模型會根據當前的損失值計算每個參數的梯度。\n","\n","2. `nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)`: 這個函數用於梯度裁剪，以防止梯度爆炸的問題。梯度裁剪的目的是限制梯度的範圍，確保其不超過預定的最大範圍。在這裡，我們使用`max_norm`參數設定梯度的最大範圍為1.0。\n","\n","3. `optimizer.step()`: 這個方法根據計算得到的梯度更新模型的參數。優化器會根據設定的學習率和梯度更新策略來更新參數的值，使得損失函數下降。\n","\n","4. `scheduler.step()`: 這個方法用於調整優化器的學習率。在這裡使用的是線性學習率調整器(`get_linear_schedule_with_warmup`)，它會根據設定的參數在每個訓練步驟中調整學習率的值。\n","\n","5. `optimizer.zero_grad()`: 這個方法將模型參數的梯度清零，以便進行下一個batch的計算。在進行參數更新之前，需要先將梯度清零，以避免梯度的累積影響下一個batch的計算。\n","\n","總結起來，這一段程式碼的作用是執行反向傳播，計算梯度並更新模型的參數。同時，通過梯度裁剪、學習率調整和梯度清零等操作，確保訓練過程的穩定和正確進行。\n","\n","讓我們寫另一個函數，幫助我們在給定的數據加載器上評估模型："],"metadata":{"id":"z9zf0OI7DAQw"}},{"cell_type":"code","source":["def eval_model_gpu(model, data_loader, loss_fn, device, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"k_rmFFhYDCBm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_model_cpu(model, data_loader, loss_fn, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"]\n","      attention_mask = d[\"attention_mask\"]\n","      targets = d[\"targets\"]\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","\n","      loss = loss_fn(outputs, targets)\n","\n","      correct_predictions += torch.sum(preds == targets)\n","      losses.append(loss.item())\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses)"],"metadata":{"id":"F_MQXf3F_lf-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 下面開始訓練模型但要買資源"],"metadata":{"id":"Hggf7zNDBv2-"}},{"cell_type":"code","source":["from collections import defaultdict"],"metadata":{"id":"uaM5kdKGERIs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time"],"metadata":{"id":"qSS37zP3HiYV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","start_time = time.time()\n","\n","history = defaultdict(list)\n","best_accuracy = 0\n","\n","for epoch in range(EPOCHS):\n","\n","  print(f'Epoch {epoch + 1}/{EPOCHS}')\n","  print('-' * 10)\n","\n","  train_acc, train_loss = train_epoch_gpu(\n","    model,\n","    train_data_loader,    \n","    loss_fn, \n","    optimizer, \n","    device, \n","    scheduler, \n","    len(df_train)\n","  )\n","\n","  print(f'Train loss {train_loss} accuracy {train_acc}')\n","\n","  val_acc, val_loss = eval_model_gpu(\n","    model,\n","    val_data_loader,\n","    loss_fn, \n","    device, \n","    len(df_val)\n","  )\n","\n","  print(f'Val   loss {val_loss} accuracy {val_acc}')\n","  print()\n","\n","  history['train_acc'].append(train_acc)\n","  history['train_loss'].append(train_loss)\n","  history['val_acc'].append(val_acc)\n","  history['val_loss'].append(val_loss)\n","\n","  if val_acc > best_accuracy:\n","    torch.save(model.state_dict(), 'best_model_state.bin')\n","    best_accuracy = val_acc\n","\n","end_time = time.time()\n","execution_time = end_time - start_time\n","print(\"Execution time:\", execution_time)"],"metadata":{"id":"2HQcg-onD6Bs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e132d12d-67bd-49b7-80fc-4cf49b1599f1","executionInfo":{"status":"ok","timestamp":1685285503265,"user_tz":-480,"elapsed":494059,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.8306024580930187 accuracy 0.5788888888888889\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.7431705338614327 accuracy 0.67\n","\n","Epoch 2/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.7509292379944725 accuracy 0.6611111111111111\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.8325371359075818 accuracy 0.65\n","\n","Epoch 3/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.7419162804046563 accuracy 0.6877777777777778\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.8338071193013873 accuracy 0.66\n","\n","Epoch 4/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.6831925337293506 accuracy 0.7238888888888889\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.9800507852009365 accuracy 0.61\n","\n","Epoch 5/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.6280802348546223 accuracy 0.7627777777777778\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.8845466205051967 accuracy 0.64\n","\n","Epoch 6/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.5912187125830524 accuracy 0.7955555555555556\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.9260453837258475 accuracy 0.61\n","\n","Epoch 7/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.546031499462845 accuracy 0.8138888888888889\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.8780410630362374 accuracy 0.67\n","\n","Epoch 8/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.5174083810596339 accuracy 0.8372222222222222\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 1.0382854385035378 accuracy 0.63\n","\n","Epoch 9/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.49231906169283707 accuracy 0.8472222222222222\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 1.1350161858967371 accuracy 0.6\n","\n","Epoch 10/10\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Train loss 0.49059419986684766 accuracy 0.85\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Val   loss 0.9531845663275037 accuracy 0.65\n","\n","Execution time: 494.1372413635254\n"]}]},{"cell_type":"code","source":["history['train_acc']"],"metadata":{"id":"GHujWGi7hpMr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285503266,"user_tz":-480,"elapsed":44,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"ba356a86-99e4-4dfe-bb8f-c2015fc7ba94"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor(0.5789, device='cuda:0', dtype=torch.float64),\n"," tensor(0.6611, device='cuda:0', dtype=torch.float64),\n"," tensor(0.6878, device='cuda:0', dtype=torch.float64),\n"," tensor(0.7239, device='cuda:0', dtype=torch.float64),\n"," tensor(0.7628, device='cuda:0', dtype=torch.float64),\n"," tensor(0.7956, device='cuda:0', dtype=torch.float64),\n"," tensor(0.8139, device='cuda:0', dtype=torch.float64),\n"," tensor(0.8372, device='cuda:0', dtype=torch.float64),\n"," tensor(0.8472, device='cuda:0', dtype=torch.float64),\n"," tensor(0.8500, device='cuda:0', dtype=torch.float64)]"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["train_acc = [history['train_acc'][i].tolist() for i in range(10)]\n","train_acc"],"metadata":{"id":"n4SBUcf-efrG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285503268,"user_tz":-480,"elapsed":38,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"7a71fa40-4a4f-4eab-abb0-4bb832d8e9a0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.5788888888888889,\n"," 0.6611111111111111,\n"," 0.6877777777777778,\n"," 0.7238888888888889,\n"," 0.7627777777777778,\n"," 0.7955555555555556,\n"," 0.8138888888888889,\n"," 0.8372222222222222,\n"," 0.8472222222222222,\n"," 0.85]"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["val_acc = [history['val_acc'][i].tolist() for i in range(10)]\n","val_acc"],"metadata":{"id":"S8FZLMhehwqY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285503270,"user_tz":-480,"elapsed":37,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"688bf39e-17b6-4471-b243-ff0062299ffa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.67, 0.65, 0.66, 0.61, 0.64, 0.61, 0.67, 0.63, 0.6, 0.65]"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["會儲存最佳模型的狀態，該狀態由最高準確度表示。"],"metadata":{"id":"u9QNlJ3-EZNE"}},{"cell_type":"code","source":["# 畫圖看結果\n","plt.plot(train_acc, label='train accuracy')\n","plt.plot(val_acc, label='validation accuracy')\n","\n","plt.title('Training history')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend()\n","plt.ylim([0, 1]);"],"metadata":{"id":"e2ee4yfeEybc","colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"status":"ok","timestamp":1685285503271,"user_tz":-480,"elapsed":34,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"45b59b7f-e582-4828-c8c1-bec422cf7961"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Evaluation"],"metadata":{"id":"c3KfI8EnFKct"}},{"cell_type":"code","source":["test_acc, _ = eval_model_gpu(\n","  model,\n","  test_data_loader,\n","  loss_fn,\n","  device,\n","  len(df_test)\n",")\n","\n","test_acc.item()"],"metadata":{"id":"a0wfA7o9FBcb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285504734,"user_tz":-480,"elapsed":1479,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"84fb3557-4509-4f33-d854-eb571f4c92d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["0.68"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# using gpu\n","def get_predictions(model, data_loader):\n","  model = model.eval()\n","  \n","  content_texts = []\n","  predictions = []\n","  prediction_probs = []\n","  real_values = []\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","\n","      texts = d[\"content_text\"]\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      targets = d[\"targets\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      _, preds = torch.max(outputs, dim=1)\n","      print(preds)\n","      \n","\n","      probs = F.softmax(outputs, dim=1)\n","\n","      content_texts.extend(texts)\n","      predictions.extend(preds)\n","      prediction_probs.extend(probs)\n","      real_values.extend(targets)\n","\n","  predictions = torch.stack(predictions).cpu()\n","  prediction_probs = torch.stack(prediction_probs).cpu()\n","  real_values = torch.stack(real_values).cpu()\n","  return content_texts, predictions, prediction_probs, real_values"],"metadata":{"id":"lDtiSSpQFzqE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_content_texts, y_pred, y_pred_probs, y_test = get_predictions(\n","  model,\n","  test_data_loader\n",")"],"metadata":{"id":"w4s50rEoIzmp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506124,"user_tz":-480,"elapsed":1410,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"5fdc437b-1209-4bcd-a833-cd71531facf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","print(classification_report(y_test, y_pred, target_names=class_names))"],"metadata":{"id":"mLiqD-05JM0Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506124,"user_tz":-480,"elapsed":23,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"abc62170-0f12-4ebb-d51c-851a77f18020"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           N       0.00      0.00      0.00         8\n","           M       0.72      0.73      0.73        56\n","           P       0.63      0.75      0.68        36\n","\n","    accuracy                           0.68       100\n","   macro avg       0.45      0.49      0.47       100\n","weighted avg       0.63      0.68      0.65       100\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["def show_confusion_matrix(confusion_matrix):\n","  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n","  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n","  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n","  plt.ylabel('True sentiment')\n","  plt.xlabel('Predicted sentiment');\n","\n","cm = confusion_matrix(y_test, y_pred)\n","df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n","show_confusion_matrix(df_cm)"],"metadata":{"id":"osPpl4-YJXDD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506125,"user_tz":-480,"elapsed":19,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"f385193c-cdf1-4a71-9a3d-0e2106cc281e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## 後面就是看模型的結果"],"metadata":{"id":"oFAsEQhrKEeH"}},{"cell_type":"code","source":["idx = 2\n","\n","content_text = y_content_texts[idx]\n","true_sentiment = y_test[idx]\n","pred_df = pd.DataFrame({\n","  'class_names': class_names,\n","  'values': y_pred_probs[idx]\n","})"],"metadata":{"id":"767_qqGCKBmb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from textwrap import wrap\n","print(\"\\n\".join(wrap(content_text)))\n","print()\n","print(f'True sentiment: {class_names[true_sentiment]}')"],"metadata":{"id":"vce5JF7uKRCG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506127,"user_tz":-480,"elapsed":17,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"b4fd6d0d-f33d-40af-a824-e5bf3f986cd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["今日大溪老街一日遊大溪老街怎麼吃先幫大家嚐鮮原本想吃個豆花但太撐了沒吃大溪老街老阿伯現滷豆干位在大溪老街走到底運動中心左轉推薦順序豆包百葉黃\n","金蛋素雞海帶豆干以上是我們點的共超多超飽豆包超入味百葉很嫩其他蠻普通的辣醬很好吃但會辣喔阿嬤小吃店香腸米腸一號餐米腸米血香腸香腸烤過米腸米血\n","是蒸的我覺得香腸烤不夠脆米腸我也覺得烤的比較好吃米血也沒什麼豬血糕的味道豬血湯有加小腸料很多湯頭其實不錯喝但我還是喜歡沙茶加到爆的豬血湯元鳥\n","蛋這家應該是大溪老街最便宜鳥蛋元烤玉米大溪老街最便宜烤玉米整整比台北便宜兩倍玉米是糯米玉米沒錯不過口味偏甜我吃好久一直以為他是甜玉米元炸熱狗\n","招牌是寫熱狗沒想到收錢收可能是裹粉的價格不一樣我們點小隻的冬瓜茶位在老阿伯現滷豆干對面一個阿嬤開的有金吉檸檬跟冬瓜茶還有貢丸湯冬瓜茶不會到很\n","甜但冬瓜味也沒有到很濃郁不過配豆干蠻適合的我們從大溪老街頭順路吃下去的順序香腸鳥蛋玉米熱狗冬瓜茶豆乾給大家參考喜歡我食記可以追蹤我IG\n","\n","True sentiment: M\n"]}]},{"cell_type":"code","source":["sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n","plt.ylabel('sentiment')\n","plt.xlabel('probability')\n","plt.xlim([0, 1]);"],"metadata":{"id":"UD5hpkf_LC8u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685285506482,"user_tz":-480,"elapsed":365,"user":{"displayName":"曹灝翰","userId":"00262753423893401071"}},"outputId":"02c5c7ee-e843-4c68-dcd9-8c496ad6c4b2"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# 儲存模型"],"metadata":{"id":"krdJ5hEuNSlu"}},{"cell_type":"code","source":["save_path = \"model_file/sentiment_classification_model.pth\"\n","torch.save(model.state_dict(), save_path)"],"metadata":{"id":"zz0gtCzWNSEN"},"execution_count":null,"outputs":[]}]}